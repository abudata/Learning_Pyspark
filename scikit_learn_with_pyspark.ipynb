{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Using scikit-learn locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "# Generate test and train sets\n",
    "size = len(iris.target)\n",
    "indices = np.random.permutation(size)\n",
    "\n",
    "cutoff = int(size * .30)\n",
    "\n",
    "testX = iris.data[indices[0:cutoff],:]\n",
    "trainX = iris.data[indices[cutoff:],:]\n",
    "testY = iris.target[indices[0:cutoff]]\n",
    "trainY = iris.target[indices[cutoff:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.3,  3.3,  6. ,  2.5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create a KNeighborsClassifier using the default settings\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(trainX, trainY)\n",
    "\n",
    "predictions = knn.predict(testX)\n",
    "\n",
    "# Print out the accuracy of the classifier on the test set\n",
    "print(sum(predictions == testY) / float(len(testY)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:  Using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One can import train_test_split from model_selection method of sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "def runNearestNeighbors(k):\n",
    "    # Load dataset from sklearn.datasets\n",
    "    irisData = datasets.load_iris()\n",
    "    \n",
    "    # Split into train and test using sklearn.cross_validation.train_test_split\n",
    "    yTrain, yTest, XTrain, XTest = train_test_split(irisData.target, \n",
    "                                                    irisData.data)\n",
    "    \n",
    "    # Build the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(XTrain, yTrain)\n",
    "    \n",
    "    # Calculate predictions and accuracy\n",
    "    predictions = knn.predict(XTest)\n",
    "    accuracy = (predictions == yTest).sum() / float(len(yTest))\n",
    "    \n",
    "    return (k, accuracy)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pyspark library\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.97368421052631582)\n",
      "(2, 0.97368421052631582)\n",
      "(3, 0.97368421052631582)\n",
      "(4, 0.94736842105263153)\n",
      "(5, 0.92105263157894735)\n",
      "(6, 0.97368421052631582)\n",
      "(7, 0.97368421052631582)\n",
      "(8, 0.97368421052631582)\n",
      "(9, 0.97368421052631582)\n",
      "(10, 0.97368421052631582)\n"
     ]
    }
   ],
   "source": [
    "k = sc.parallelize(range(1, 11))\n",
    "results = k.map(runNearestNeighbors)\n",
    "print ('\\n'.join(map(str, results.collect())))\n",
    "print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Spark version \n",
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transfer the data using a Broadcast instead of loading it at each excecutor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.97368421052631582)\n",
      "(2, 0.97368421052631582)\n",
      "(3, 0.97368421052631582)\n",
      "(4, 0.97368421052631582)\n",
      "(5, 0.97368421052631582)\n",
      "(6, 0.97368421052631582)\n",
      "(7, 0.97368421052631582)\n",
      "(8, 0.97368421052631582)\n",
      "(9, 0.97368421052631582)\n",
      "(10, 0.97368421052631582)\n"
     ]
    }
   ],
   "source": [
    "# Creating the Broadcast variable\n",
    "irisBroadcast = sc.broadcast(iris)\n",
    "\n",
    "def runNearestNeighborsBroadcast(k):\n",
    "    # Using the data in the irisBroadcast variable split into train and test using \n",
    "    # sklearn.cross_validation.train_test_split\n",
    "    yTrain, yTest, XTrain, XTest = train_test_split(irisBroadcast.value.target,\n",
    "                                                   irisBroadcast.value.data, random_state=0)\n",
    "    \n",
    "    # Building the model\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(XTrain, yTrain)\n",
    "    \n",
    "    # Calculating predictions and accuracy\n",
    "    predictions = knn.predict(XTest)\n",
    "    accuracy = (predictions == yTest).sum() / float(len(yTest))\n",
    "    \n",
    "    return (k, accuracy)\n",
    "\n",
    "# Rerun grid search\n",
    "k = sc.parallelize(range(1, 11))\n",
    "results = k.map(runNearestNeighborsBroadcast)\n",
    "print('\\n'.join(map(str, results.collect())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "<generator object _PartitionIterator.__iter__ at 0x7f8af0ed69e8>\n"
     ]
    }
   ],
   "source": [
    "# Creating indices for 10-fold cross validation\n",
    "kf = KFold(size, n_folds=10)\n",
    "print(len(kf))\n",
    "print(kf.__iter__())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KFold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
